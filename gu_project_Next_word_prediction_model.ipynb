{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyotibangari/Next-Word-Prediction-Model/blob/main/gu_project_Next_word_prediction_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-Le9PUgWRQl"
      },
      "outputs": [],
      "source": [
        "faqs=\"\"\"Galgotias University is a private university located in Greater Noida, Uttar Pradesh, India. It was established in 2011 by the Galgotias Educational Institutions. Here is some general information about the university:\n",
        "Location:\n",
        "Address: 1, Knowledge Park, Phase II, Greater Noida, Uttar Pradesh, India.\n",
        "Founding Year:\n",
        "Galgotias University was established in 2011.\n",
        "Ownership:\n",
        "It is a private university.223\n",
        "Accreditations:\n",
        "The university is recognized by the University Grants Commission (UGC).\n",
        "Courses and Programs:\n",
        "Galgotias University offers a variety of undergraduate, postgraduate, and doctoral programs in fields such as engineering, management, law, pharmacy, humanities, and social sciences.\n",
        "Campus and Facilities:\n",
        "The university campus is equipped with modern facilities, including well-equipped classrooms, laboratories, hostels, sports facilities, and more.\n",
        "Affiliations:\n",
        "The university is affiliated with various professional bodies and organizations related to different disciplines.\n",
        "Rankings:\n",
        "University rankings may vary, and it's recommended to check the latest rankings from reliable sources.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "FdQbzN9vXgLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token = Tokenizer()"
      ],
      "metadata": {
        "id": "WPnK5nGuXwx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token.fit_on_texts([faqs])"
      ],
      "metadata": {
        "id": "eTQeeEdSX9cQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(token.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR8xSNmxYJrZ",
        "outputId": "bebff4d1-d333-47bd-a177-9bae8deae402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "91"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KDQzPPfFgz9",
        "outputId": "e0d900a0-6a2f-4687-e458-2e0b7d672a65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'university': 1,\n",
              " 'the': 2,\n",
              " 'and': 3,\n",
              " 'is': 4,\n",
              " 'galgotias': 5,\n",
              " 'in': 6,\n",
              " 'a': 7,\n",
              " 'facilities': 8,\n",
              " 'rankings': 9,\n",
              " 'private': 10,\n",
              " 'greater': 11,\n",
              " 'noida': 12,\n",
              " 'uttar': 13,\n",
              " 'pradesh': 14,\n",
              " 'india': 15,\n",
              " 'it': 16,\n",
              " 'was': 17,\n",
              " 'established': 18,\n",
              " '2011': 19,\n",
              " 'by': 20,\n",
              " 'programs': 21,\n",
              " 'campus': 22,\n",
              " 'equipped': 23,\n",
              " 'with': 24,\n",
              " 'to': 25,\n",
              " 'located': 26,\n",
              " 'educational': 27,\n",
              " 'institutions': 28,\n",
              " 'here': 29,\n",
              " 'some': 30,\n",
              " 'general': 31,\n",
              " 'information': 32,\n",
              " 'about': 33,\n",
              " 'location': 34,\n",
              " 'address': 35,\n",
              " '1': 36,\n",
              " 'knowledge': 37,\n",
              " 'park': 38,\n",
              " 'phase': 39,\n",
              " 'ii': 40,\n",
              " 'founding': 41,\n",
              " 'year': 42,\n",
              " 'ownership': 43,\n",
              " 'accreditations': 44,\n",
              " 'recognized': 45,\n",
              " 'grants': 46,\n",
              " 'commission': 47,\n",
              " 'ugc': 48,\n",
              " 'courses': 49,\n",
              " 'offers': 50,\n",
              " 'variety': 51,\n",
              " 'of': 52,\n",
              " 'undergraduate': 53,\n",
              " 'postgraduate': 54,\n",
              " 'doctoral': 55,\n",
              " 'fields': 56,\n",
              " 'such': 57,\n",
              " 'as': 58,\n",
              " 'engineering': 59,\n",
              " 'management': 60,\n",
              " 'law': 61,\n",
              " 'pharmacy': 62,\n",
              " 'humanities': 63,\n",
              " 'social': 64,\n",
              " 'sciences': 65,\n",
              " 'modern': 66,\n",
              " 'including': 67,\n",
              " 'well': 68,\n",
              " 'classrooms': 69,\n",
              " 'laboratories': 70,\n",
              " 'hostels': 71,\n",
              " 'sports': 72,\n",
              " 'more': 73,\n",
              " 'affiliations': 74,\n",
              " 'affiliated': 75,\n",
              " 'various': 76,\n",
              " 'professional': 77,\n",
              " 'bodies': 78,\n",
              " 'organizations': 79,\n",
              " 'related': 80,\n",
              " 'different': 81,\n",
              " 'disciplines': 82,\n",
              " 'may': 83,\n",
              " 'vary': 84,\n",
              " \"it's\": 85,\n",
              " 'recommended': 86,\n",
              " 'check': 87,\n",
              " 'latest': 88,\n",
              " 'from': 89,\n",
              " 'reliable': 90,\n",
              " 'sources': 91}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for sentence  in faqs.split('\\n'):\n",
        "  # print(sentence)\n",
        "  # print(token.texts_to_sequences([sentence])[0])\n",
        "  token_sentence=token.texts_to_sequences([sentence])[0]\n",
        "  for i in range(1,len(token_sentence)):\n",
        "    input_sequences.append( token_sentence[:i+1])\n"
      ],
      "metadata": {
        "id": "m4hRK5u0Yudr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9_Eszs8ZL7F",
        "outputId": "65827386-a1b1-4416-b42f-499cd8c669df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5, 1],\n",
              " [5, 1, 4],\n",
              " [5, 1, 4, 7],\n",
              " [5, 1, 4, 7, 10],\n",
              " [5, 1, 4, 7, 10, 1],\n",
              " [5, 1, 4, 7, 10, 1, 26],\n",
              " [5, 1, 4, 7, 10, 1, 26, 6],\n",
              " [5, 1, 4, 7, 10, 1, 26, 6, 11],\n",
              " [5, 1, 4, 7, 10, 1, 26, 6, 11, 12],\n",
              " [5, 1, 4, 7, 10, 1, 26, 6, 11, 12, 13],\n",
              " [5, 1, 4, 7, 10, 1, 26, 6, 11, 12, 13, 14],\n",
              " [5, 1, 4, 7, 10, 1, 26, 6, 11, 12, 13, 14, 15],\n",
              " [5, 1, 4, 7, 10, 1, 26, 6, 11, 12, 13, 14, 15, 16],\n",
              " [5, 1, 4, 7, 10, 1, 26, 6, 11, 12, 13, 14, 15, 16, 17],\n",
              " [5, 1, 4, 7, 10, 1, 26, 6, 11, 12, 13, 14, 15, 16, 17, 18],\n",
              " [5, 1, 4, 7, 10, 1, 26, 6, 11, 12, 13, 14, 15, 16, 17, 18, 6],\n",
              " [5, 1, 4, 7, 10, 1, 26, 6, 11, 12, 13, 14, 15, 16, 17, 18, 6, 19],\n",
              " [5, 1, 4, 7, 10, 1, 26, 6, 11, 12, 13, 14, 15, 16, 17, 18, 6, 19, 20],\n",
              " [5, 1, 4, 7, 10, 1, 26, 6, 11, 12, 13, 14, 15, 16, 17, 18, 6, 19, 20, 2],\n",
              " [5, 1, 4, 7, 10, 1, 26, 6, 11, 12, 13, 14, 15, 16, 17, 18, 6, 19, 20, 2, 5],\n",
              " [5,\n",
              "  1,\n",
              "  4,\n",
              "  7,\n",
              "  10,\n",
              "  1,\n",
              "  26,\n",
              "  6,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  18,\n",
              "  6,\n",
              "  19,\n",
              "  20,\n",
              "  2,\n",
              "  5,\n",
              "  27],\n",
              " [5,\n",
              "  1,\n",
              "  4,\n",
              "  7,\n",
              "  10,\n",
              "  1,\n",
              "  26,\n",
              "  6,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  18,\n",
              "  6,\n",
              "  19,\n",
              "  20,\n",
              "  2,\n",
              "  5,\n",
              "  27,\n",
              "  28],\n",
              " [5,\n",
              "  1,\n",
              "  4,\n",
              "  7,\n",
              "  10,\n",
              "  1,\n",
              "  26,\n",
              "  6,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  18,\n",
              "  6,\n",
              "  19,\n",
              "  20,\n",
              "  2,\n",
              "  5,\n",
              "  27,\n",
              "  28,\n",
              "  29],\n",
              " [5,\n",
              "  1,\n",
              "  4,\n",
              "  7,\n",
              "  10,\n",
              "  1,\n",
              "  26,\n",
              "  6,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  18,\n",
              "  6,\n",
              "  19,\n",
              "  20,\n",
              "  2,\n",
              "  5,\n",
              "  27,\n",
              "  28,\n",
              "  29,\n",
              "  4],\n",
              " [5,\n",
              "  1,\n",
              "  4,\n",
              "  7,\n",
              "  10,\n",
              "  1,\n",
              "  26,\n",
              "  6,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  18,\n",
              "  6,\n",
              "  19,\n",
              "  20,\n",
              "  2,\n",
              "  5,\n",
              "  27,\n",
              "  28,\n",
              "  29,\n",
              "  4,\n",
              "  30],\n",
              " [5,\n",
              "  1,\n",
              "  4,\n",
              "  7,\n",
              "  10,\n",
              "  1,\n",
              "  26,\n",
              "  6,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  18,\n",
              "  6,\n",
              "  19,\n",
              "  20,\n",
              "  2,\n",
              "  5,\n",
              "  27,\n",
              "  28,\n",
              "  29,\n",
              "  4,\n",
              "  30,\n",
              "  31],\n",
              " [5,\n",
              "  1,\n",
              "  4,\n",
              "  7,\n",
              "  10,\n",
              "  1,\n",
              "  26,\n",
              "  6,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  18,\n",
              "  6,\n",
              "  19,\n",
              "  20,\n",
              "  2,\n",
              "  5,\n",
              "  27,\n",
              "  28,\n",
              "  29,\n",
              "  4,\n",
              "  30,\n",
              "  31,\n",
              "  32],\n",
              " [5,\n",
              "  1,\n",
              "  4,\n",
              "  7,\n",
              "  10,\n",
              "  1,\n",
              "  26,\n",
              "  6,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  18,\n",
              "  6,\n",
              "  19,\n",
              "  20,\n",
              "  2,\n",
              "  5,\n",
              "  27,\n",
              "  28,\n",
              "  29,\n",
              "  4,\n",
              "  30,\n",
              "  31,\n",
              "  32,\n",
              "  33],\n",
              " [5,\n",
              "  1,\n",
              "  4,\n",
              "  7,\n",
              "  10,\n",
              "  1,\n",
              "  26,\n",
              "  6,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  18,\n",
              "  6,\n",
              "  19,\n",
              "  20,\n",
              "  2,\n",
              "  5,\n",
              "  27,\n",
              "  28,\n",
              "  29,\n",
              "  4,\n",
              "  30,\n",
              "  31,\n",
              "  32,\n",
              "  33,\n",
              "  2],\n",
              " [5,\n",
              "  1,\n",
              "  4,\n",
              "  7,\n",
              "  10,\n",
              "  1,\n",
              "  26,\n",
              "  6,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  18,\n",
              "  6,\n",
              "  19,\n",
              "  20,\n",
              "  2,\n",
              "  5,\n",
              "  27,\n",
              "  28,\n",
              "  29,\n",
              "  4,\n",
              "  30,\n",
              "  31,\n",
              "  32,\n",
              "  33,\n",
              "  2,\n",
              "  1],\n",
              " [35, 36],\n",
              " [35, 36, 37],\n",
              " [35, 36, 37, 38],\n",
              " [35, 36, 37, 38, 39],\n",
              " [35, 36, 37, 38, 39, 40],\n",
              " [35, 36, 37, 38, 39, 40, 11],\n",
              " [35, 36, 37, 38, 39, 40, 11, 12],\n",
              " [35, 36, 37, 38, 39, 40, 11, 12, 13],\n",
              " [35, 36, 37, 38, 39, 40, 11, 12, 13, 14],\n",
              " [35, 36, 37, 38, 39, 40, 11, 12, 13, 14, 15],\n",
              " [41, 42],\n",
              " [5, 1],\n",
              " [5, 1, 17],\n",
              " [5, 1, 17, 18],\n",
              " [5, 1, 17, 18, 6],\n",
              " [5, 1, 17, 18, 6, 19],\n",
              " [16, 4],\n",
              " [16, 4, 7],\n",
              " [16, 4, 7, 10],\n",
              " [16, 4, 7, 10, 1],\n",
              " [2, 1],\n",
              " [2, 1, 4],\n",
              " [2, 1, 4, 45],\n",
              " [2, 1, 4, 45, 20],\n",
              " [2, 1, 4, 45, 20, 2],\n",
              " [2, 1, 4, 45, 20, 2, 1],\n",
              " [2, 1, 4, 45, 20, 2, 1, 46],\n",
              " [2, 1, 4, 45, 20, 2, 1, 46, 47],\n",
              " [2, 1, 4, 45, 20, 2, 1, 46, 47, 48],\n",
              " [49, 3],\n",
              " [49, 3, 21],\n",
              " [5, 1],\n",
              " [5, 1, 50],\n",
              " [5, 1, 50, 7],\n",
              " [5, 1, 50, 7, 51],\n",
              " [5, 1, 50, 7, 51, 52],\n",
              " [5, 1, 50, 7, 51, 52, 53],\n",
              " [5, 1, 50, 7, 51, 52, 53, 54],\n",
              " [5, 1, 50, 7, 51, 52, 53, 54, 3],\n",
              " [5, 1, 50, 7, 51, 52, 53, 54, 3, 55],\n",
              " [5, 1, 50, 7, 51, 52, 53, 54, 3, 55, 21],\n",
              " [5, 1, 50, 7, 51, 52, 53, 54, 3, 55, 21, 6],\n",
              " [5, 1, 50, 7, 51, 52, 53, 54, 3, 55, 21, 6, 56],\n",
              " [5, 1, 50, 7, 51, 52, 53, 54, 3, 55, 21, 6, 56, 57],\n",
              " [5, 1, 50, 7, 51, 52, 53, 54, 3, 55, 21, 6, 56, 57, 58],\n",
              " [5, 1, 50, 7, 51, 52, 53, 54, 3, 55, 21, 6, 56, 57, 58, 59],\n",
              " [5, 1, 50, 7, 51, 52, 53, 54, 3, 55, 21, 6, 56, 57, 58, 59, 60],\n",
              " [5, 1, 50, 7, 51, 52, 53, 54, 3, 55, 21, 6, 56, 57, 58, 59, 60, 61],\n",
              " [5, 1, 50, 7, 51, 52, 53, 54, 3, 55, 21, 6, 56, 57, 58, 59, 60, 61, 62],\n",
              " [5, 1, 50, 7, 51, 52, 53, 54, 3, 55, 21, 6, 56, 57, 58, 59, 60, 61, 62, 63],\n",
              " [5,\n",
              "  1,\n",
              "  50,\n",
              "  7,\n",
              "  51,\n",
              "  52,\n",
              "  53,\n",
              "  54,\n",
              "  3,\n",
              "  55,\n",
              "  21,\n",
              "  6,\n",
              "  56,\n",
              "  57,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  62,\n",
              "  63,\n",
              "  3],\n",
              " [5,\n",
              "  1,\n",
              "  50,\n",
              "  7,\n",
              "  51,\n",
              "  52,\n",
              "  53,\n",
              "  54,\n",
              "  3,\n",
              "  55,\n",
              "  21,\n",
              "  6,\n",
              "  56,\n",
              "  57,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  62,\n",
              "  63,\n",
              "  3,\n",
              "  64],\n",
              " [5,\n",
              "  1,\n",
              "  50,\n",
              "  7,\n",
              "  51,\n",
              "  52,\n",
              "  53,\n",
              "  54,\n",
              "  3,\n",
              "  55,\n",
              "  21,\n",
              "  6,\n",
              "  56,\n",
              "  57,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  62,\n",
              "  63,\n",
              "  3,\n",
              "  64,\n",
              "  65],\n",
              " [22, 3],\n",
              " [22, 3, 8],\n",
              " [2, 1],\n",
              " [2, 1, 22],\n",
              " [2, 1, 22, 4],\n",
              " [2, 1, 22, 4, 23],\n",
              " [2, 1, 22, 4, 23, 24],\n",
              " [2, 1, 22, 4, 23, 24, 66],\n",
              " [2, 1, 22, 4, 23, 24, 66, 8],\n",
              " [2, 1, 22, 4, 23, 24, 66, 8, 67],\n",
              " [2, 1, 22, 4, 23, 24, 66, 8, 67, 68],\n",
              " [2, 1, 22, 4, 23, 24, 66, 8, 67, 68, 23],\n",
              " [2, 1, 22, 4, 23, 24, 66, 8, 67, 68, 23, 69],\n",
              " [2, 1, 22, 4, 23, 24, 66, 8, 67, 68, 23, 69, 70],\n",
              " [2, 1, 22, 4, 23, 24, 66, 8, 67, 68, 23, 69, 70, 71],\n",
              " [2, 1, 22, 4, 23, 24, 66, 8, 67, 68, 23, 69, 70, 71, 72],\n",
              " [2, 1, 22, 4, 23, 24, 66, 8, 67, 68, 23, 69, 70, 71, 72, 8],\n",
              " [2, 1, 22, 4, 23, 24, 66, 8, 67, 68, 23, 69, 70, 71, 72, 8, 3],\n",
              " [2, 1, 22, 4, 23, 24, 66, 8, 67, 68, 23, 69, 70, 71, 72, 8, 3, 73],\n",
              " [2, 1],\n",
              " [2, 1, 4],\n",
              " [2, 1, 4, 75],\n",
              " [2, 1, 4, 75, 24],\n",
              " [2, 1, 4, 75, 24, 76],\n",
              " [2, 1, 4, 75, 24, 76, 77],\n",
              " [2, 1, 4, 75, 24, 76, 77, 78],\n",
              " [2, 1, 4, 75, 24, 76, 77, 78, 3],\n",
              " [2, 1, 4, 75, 24, 76, 77, 78, 3, 79],\n",
              " [2, 1, 4, 75, 24, 76, 77, 78, 3, 79, 80],\n",
              " [2, 1, 4, 75, 24, 76, 77, 78, 3, 79, 80, 25],\n",
              " [2, 1, 4, 75, 24, 76, 77, 78, 3, 79, 80, 25, 81],\n",
              " [2, 1, 4, 75, 24, 76, 77, 78, 3, 79, 80, 25, 81, 82],\n",
              " [1, 9],\n",
              " [1, 9, 83],\n",
              " [1, 9, 83, 84],\n",
              " [1, 9, 83, 84, 3],\n",
              " [1, 9, 83, 84, 3, 85],\n",
              " [1, 9, 83, 84, 3, 85, 86],\n",
              " [1, 9, 83, 84, 3, 85, 86, 25],\n",
              " [1, 9, 83, 84, 3, 85, 86, 25, 87],\n",
              " [1, 9, 83, 84, 3, 85, 86, 25, 87, 2],\n",
              " [1, 9, 83, 84, 3, 85, 86, 25, 87, 2, 88],\n",
              " [1, 9, 83, 84, 3, 85, 86, 25, 87, 2, 88, 9],\n",
              " [1, 9, 83, 84, 3, 85, 86, 25, 87, 2, 88, 9, 89],\n",
              " [1, 9, 83, 84, 3, 85, 86, 25, 87, 2, 88, 9, 89, 90],\n",
              " [1, 9, 83, 84, 3, 85, 86, 25, 87, 2, 88, 9, 89, 90, 91]]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len =max([len(x) for x in input_sequences])\n",
        "print(max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ltd-pnOFblTu",
        "outputId": "1bba4223-a523-49e0-ad55-ccefcc19d8ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_input_sequences = pad_sequences(input_sequences, maxlen = max_len, padding='pre')"
      ],
      "metadata": {
        "id": "RhmDErpTcInK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(padded_input_sequences)"
      ],
      "metadata": {
        "id": "FNQx_13Aco-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_input_sequences[:,:-1]"
      ],
      "metadata": {
        "id": "sE8t1-Jyc5DO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = padded_input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "Pw2DQekadL_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWfaKc7ddRoK",
        "outputId": "f6bf5ffd-0bec-45a7-bedf-cd4a446a7386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(129, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjSsMDC9dUBM",
        "outputId": "39f4e828-ba0b-46a4-8031-7abfeb12c7d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(129,)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "Y = to_categorical(Y,num_classes=92)"
      ],
      "metadata": {
        "id": "aby5Uy6-da1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEVu3xDCUd4c",
        "outputId": "e737c6b9-d568-48d8-86a8-be18246880ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(129, 92)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,LSTM,Dense"
      ],
      "metadata": {
        "id": "ABu0bfzIU1SW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(92,100,input_length=30))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(92, activation=\"softmax\"))\n"
      ],
      "metadata": {
        "id": "aOteiL99V5xC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "3jtbLIZtXL-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYrwWJdoXd94",
        "outputId": "b603d1e8-6068-46f0-df44-e233c99a006a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 30, 100)           9200      \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 150)               150600    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 92)                13892     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 173692 (678.48 KB)\n",
            "Trainable params: 173692 (678.48 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,Y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VhoQ471Xg6P",
        "outputId": "36f4afdb-0fc3-4f27-e110-f10b5f6ea9cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 3s 50ms/step - loss: 4.5193 - accuracy: 0.0388\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 4.4876 - accuracy: 0.0775\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 4.4290 - accuracy: 0.0775\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 4.3242 - accuracy: 0.0775\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 4.2625 - accuracy: 0.0775\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 4.2491 - accuracy: 0.0930\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 4.2070 - accuracy: 0.0775\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 4.2961 - accuracy: 0.0775\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 54ms/step - loss: 4.2460 - accuracy: 0.0775\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 4.1673 - accuracy: 0.0775\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 4.1801 - accuracy: 0.0930\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 4.1371 - accuracy: 0.1008\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 4.1263 - accuracy: 0.1008\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 4.1220 - accuracy: 0.0853\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 4.0435 - accuracy: 0.1318\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 4.0696 - accuracy: 0.1550\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 4.0025 - accuracy: 0.1550\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 3.9407 - accuracy: 0.1240\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 3.8826 - accuracy: 0.1240\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 3.8551 - accuracy: 0.1628\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 3.7871 - accuracy: 0.1395\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 3.7628 - accuracy: 0.1008\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 3.6841 - accuracy: 0.1395\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 3.6580 - accuracy: 0.1395\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 3.5854 - accuracy: 0.1395\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 3.5363 - accuracy: 0.1628\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 3.5159 - accuracy: 0.1860\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 3.4827 - accuracy: 0.1705\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 3.4353 - accuracy: 0.1473\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 3.3962 - accuracy: 0.1550\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 3.3242 - accuracy: 0.1628\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 3.2646 - accuracy: 0.1550\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 3.2229 - accuracy: 0.2171\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 3.1588 - accuracy: 0.2248\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 3.1007 - accuracy: 0.2016\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 3.0357 - accuracy: 0.2248\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 54ms/step - loss: 2.9794 - accuracy: 0.2093\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 2.9413 - accuracy: 0.2248\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 1s 98ms/step - loss: 2.9079 - accuracy: 0.2248\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 90ms/step - loss: 2.8550 - accuracy: 0.2326\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 88ms/step - loss: 2.8153 - accuracy: 0.2481\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 1s 98ms/step - loss: 2.7757 - accuracy: 0.2403\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 2.6756 - accuracy: 0.2636\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 2.6638 - accuracy: 0.2481\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 2.6053 - accuracy: 0.2481\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 2.5397 - accuracy: 0.3023\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 2.5222 - accuracy: 0.3256\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 2.4615 - accuracy: 0.3411\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 2.3990 - accuracy: 0.3488\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 2.3476 - accuracy: 0.3101\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 2.3062 - accuracy: 0.3178\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 2.2543 - accuracy: 0.3643\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 2.2000 - accuracy: 0.3643\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 2.1662 - accuracy: 0.3566\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 2.1291 - accuracy: 0.3798\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 2.0965 - accuracy: 0.3953\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 2.0460 - accuracy: 0.4651\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 2.0241 - accuracy: 0.4341\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 1.9928 - accuracy: 0.3953\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 1.9665 - accuracy: 0.4109\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 1.9575 - accuracy: 0.4109\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 1.9176 - accuracy: 0.4341\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 1.8655 - accuracy: 0.4651\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 1.8483 - accuracy: 0.4651\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 1.8424 - accuracy: 0.4806\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 1.8103 - accuracy: 0.4574\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 1.7413 - accuracy: 0.5116\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 1.7074 - accuracy: 0.5194\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 1.6514 - accuracy: 0.5426\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 1.6157 - accuracy: 0.6124\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 1.6069 - accuracy: 0.5736\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 1.6056 - accuracy: 0.5349\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 1.5482 - accuracy: 0.6047\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 1.5441 - accuracy: 0.5891\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 1.5423 - accuracy: 0.5891\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 1.5055 - accuracy: 0.6202\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 1.4813 - accuracy: 0.6744\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 1.4524 - accuracy: 0.6822\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 1.4237 - accuracy: 0.7132\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 1.4003 - accuracy: 0.6899\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 85ms/step - loss: 1.3938 - accuracy: 0.6744\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 87ms/step - loss: 1.3909 - accuracy: 0.6589\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 92ms/step - loss: 1.3709 - accuracy: 0.6434\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 88ms/step - loss: 1.3540 - accuracy: 0.6512\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 89ms/step - loss: 1.3611 - accuracy: 0.6899\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 1.3255 - accuracy: 0.7287\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 54ms/step - loss: 1.3011 - accuracy: 0.7364\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 1.2645 - accuracy: 0.7519\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 1.2470 - accuracy: 0.7209\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 1.2175 - accuracy: 0.7597\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 1.2174 - accuracy: 0.7829\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 1.1837 - accuracy: 0.7752\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 1.1417 - accuracy: 0.7752\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 1.1722 - accuracy: 0.7364\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 1.1694 - accuracy: 0.7132\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 1.1533 - accuracy: 0.7519\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 1.1406 - accuracy: 0.7519\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 1.1072 - accuracy: 0.7519\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 1.0693 - accuracy: 0.7829\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 1.0627 - accuracy: 0.7752\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b01e0099e70>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "r_ZzBSQ0eg1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "hdEEhwONZMnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "text = input(\"enter text : \")\n",
        "\n",
        "for i in range(5):\n",
        "  # tokenize\n",
        "  token_text = token.texts_to_sequences([text])[0]\n",
        "  # padding\n",
        "  padded_token_text = pad_sequences([token_text], maxlen=30, padding='pre')\n",
        "  # predict\n",
        "  pos = np.argmax(model.predict(padded_token_text))\n",
        "\n",
        "  for word,index in token.word_index.items():\n",
        "    if index == pos:\n",
        "      text = text + \" \" +word\n",
        "      print(text)\n",
        "      # time.sleep(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZ_Qel3BbVci",
        "outputId": "38d0534a-8664-48a3-c7b6-789b8661db96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter text : the\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "the university\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "the university is\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "the university is recognized\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "the university is recognized by\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "the university is recognized by the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dujWlMirbk2A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}